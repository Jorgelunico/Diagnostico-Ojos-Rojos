{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YUTAOTdHqjr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split      # dividing the dataset\n",
    "from sklearn.preprocessing import LabelEncoder            # for converting str labels to number\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import random\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0 = all messages, 1 = filter INFO, 2 = filter WARNING, 3 = filter ERROR\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint ,Callback # type: ignore\n",
    "from tensorflow.keras import layers, models ,optimizers # type: ignore\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D # type: ignore\n",
    "from tensorflow.keras.applications import EfficientNetB0 # type: ignore\n",
    "import pathlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1752205821361,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "qE-zq1ZbIB7u",
    "outputId": "14a1e28e-cc7d-4a27-e64d-408c13541502"
   },
   "outputs": [],
   "source": [
    "print(\"tf\",tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138705,
     "status": "ok",
     "timestamp": 1752205960046,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "fj1c7-hnILay",
    "outputId": "e8e093e4-3a9c-44e7-a2ee-7950a8e06b87"
   },
   "outputs": [],
   "source": [
    "# Basic review of the photos directory\n",
    "\n",
    "def dataset_analysis(path):\n",
    "    subfolders = os.listdir(path)\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            files = os.listdir(subfolder_path)\n",
    "            format_dimensions_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "            for file in files:\n",
    "                try:\n",
    "                    file_path = os.path.join(subfolder_path, file)\n",
    "                    with Image.open(file_path) as img:\n",
    "                        image_type = img.format.upper()  # Format (e.g., JPEG, PNG)\n",
    "                        image_dimensions = img.size  # (width, height)\n",
    "                        image_mode = img.mode  # Mode (e.g., RGB, L)\n",
    "\n",
    "\n",
    "                        # Calculate bit depth\n",
    "                        if image_mode == \"1\":  # 1-bit pixels, black and white, stored with one pixel per byte\n",
    "                            bit_depth = 1\n",
    "                        elif image_mode == \"L\":  # 8-bit pixels, grayscale\n",
    "                            bit_depth = 8\n",
    "                        elif image_mode == \"P\":  # 8-bit pixels, mapped to any other mode using a color palette\n",
    "                            bit_depth = 8\n",
    "                        elif image_mode == \"RGB\":  # 8-bit pixels, true color\n",
    "                            bit_depth = 24  # 8 bits per channel\n",
    "                        elif image_mode == \"RGBA\":  # 8-bit pixels, true color with transparency mask\n",
    "                            bit_depth = 32  # 8 bits per channel\n",
    "                        elif image_mode == \"CMYK\":  # 8-bit pixels, color separation\n",
    "                            bit_depth = 32  # 8 bits per channel\n",
    "                        else:\n",
    "                            bit_depth = \"Unknown\"\n",
    "\n",
    "                        format_dimensions_counts[image_type][(image_dimensions, bit_depth)][image_mode] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception processing '{file}' in '{subfolder}': {e}\")\n",
    "\n",
    "            print('--------'*10)\n",
    "            print(f\"Subfolder '{subfolder}' contains ({len(files)} files):\")\n",
    "            for format, dimensions_counts in format_dimensions_counts.items():\n",
    "                print(f\"- {sum(sum(counts.values()) for counts in dimensions_counts.values())} images of format {format}:\")\n",
    "                for (dimensions, bit_depth), counts in dimensions_counts.items():\n",
    "                    for mode, count in counts.items():\n",
    "                        print(f\"  - {count} images with dimensions {dimensions}, bit depth {bit_depth}, mode {mode}\")\n",
    "\n",
    "\n",
    "\n",
    "# Cargar datos\n",
    "from google.colab import drive\n",
    "# Montar Google Drive\n",
    "drive.mount('/content/drive/')\n",
    "# Ahora puedes acceder a tus archivos\n",
    "# La ruta generalmente es: /content/drive/MyDrive/\n",
    "path = r'/content/drive/MyDrive/dataset'\n",
    "dataset_path = path\n",
    "dataset_analysis(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1752205960220,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "sbr21_Q2IoCW",
    "outputId": "98186620-dd45-49ae-8df4-8b55e24533f1"
   },
   "outputs": [],
   "source": [
    "# Count the number of images in each directory\n",
    "subfolders = os.listdir(path)\n",
    "\n",
    "image_counts = []\n",
    "for directory in subfolders:\n",
    "    sub_dir = os.path.join(path, directory)\n",
    "    if os.path.isdir(sub_dir):\n",
    "        file_count = len(os.listdir(sub_dir))\n",
    "        image_counts.append(file_count)\n",
    "\n",
    "#Add value counts on each bar\n",
    "for i in range(len(subfolders)):\n",
    "    plt.text(i, image_counts[i], str(image_counts[i]), ha='center', va='bottom')\n",
    "\n",
    "#Set some colors\n",
    "colors = ['lightskyblue', 'mediumseagreen', 'indianred', 'orange']\n",
    "\n",
    "# Plotting the results\n",
    "plt.bar(subfolders, image_counts, color=colors)\n",
    "plt.xlabel('Directory')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Directory')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 9850,
     "status": "ok",
     "timestamp": 1752205970071,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "PA_MVa9gIpSj",
    "outputId": "daaf650c-c711-41a2-c31d-31dc9097f9e5"
   },
   "outputs": [],
   "source": [
    "# Check the photos by size\n",
    "\n",
    "def dataset_size_analysis(path):\n",
    "    format_dimensions_counts = defaultdict(int)\n",
    "\n",
    "    subfolders = os.listdir(path)\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            files = os.listdir(subfolder_path)\n",
    "\n",
    "            for file in files:\n",
    "                try:\n",
    "                    file_path = os.path.join(subfolder_path, file)\n",
    "                    with Image.open(file_path) as img:\n",
    "                        image_dimensions = img.size\n",
    "                        image_mode = img.mode\n",
    "\n",
    "                        # Calculate bit depth\n",
    "                        bit_depth = {\n",
    "                            \"1\": 1,\n",
    "                            \"L\": 8,\n",
    "                            \"P\": 8,\n",
    "                            \"RGB\": 24,\n",
    "                            \"RGBA\": 32,\n",
    "                            \"CMYK\": 32\n",
    "                        }.get(image_mode, \"Unknown\")\n",
    "\n",
    "                        # Update counts\n",
    "                        format_dimensions_counts[(image_dimensions, bit_depth)] += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception processing '{file}' in '{subfolder}': {e}\")\n",
    "\n",
    "    # Plotting dimensions and bit depths\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    labels = [f\"{dims}, {depth} bit\" for (dims, depth) in format_dimensions_counts]\n",
    "    sizes = list(format_dimensions_counts.values())\n",
    "    total = sum(sizes)\n",
    "    bars = plt.bar(labels, sizes, color='blue')\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Image Distribution by Dimensions and Bit Depth')\n",
    "\n",
    "    # Adding percentage labels above the bars\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, f'{100 * yval/total:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Set the path to the dataset directory\n",
    "dataset_size_analysis(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "executionInfo": {
     "elapsed": 13617,
     "status": "ok",
     "timestamp": 1752205983691,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "Bxazji1zI3aD",
    "outputId": "dbad6c2b-7012-47c1-8090-0bc578f3a197"
   },
   "outputs": [],
   "source": [
    "def dataset_size_analysis(path):\n",
    "    # Dictionary to store counts: {subfolder: {image_size: count}}\n",
    "    folder_size_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for subfolder in os.listdir(path):\n",
    "        subfolder_path = os.path.join(path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                try:\n",
    "                    file_path = os.path.join(subfolder_path, file)\n",
    "                    with Image.open(file_path) as img:\n",
    "                        dims = img.size\n",
    "                        folder_size_counts[subfolder][dims] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception processing '{file}' in '{subfolder}': {e}\")\n",
    "\n",
    "    # Create a single plot\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Determine unique image sizes across all folders for consistent coloring and grouping\n",
    "    all_sizes = set(size for sizes in folder_size_counts.values() for size in sizes)\n",
    "    all_sizes = sorted(all_sizes, key=lambda s: (s[0] * s[1]))  # Sort by area\n",
    "\n",
    "    subfolder_names = list(folder_size_counts.keys())\n",
    "    bar_width = 0.15  # Width of bars\n",
    "    indices = range(len(subfolder_names))\n",
    "\n",
    "    for i, size in enumerate(all_sizes):\n",
    "        counts = [folder_size_counts[subfolder].get(size, 0) for subfolder in subfolder_names]\n",
    "        plt.bar([index + i * bar_width for index in indices], counts, bar_width, label=f'{size[0]}x{size[1]}')\n",
    "\n",
    "    plt.xticks([index + (len(all_sizes) - 1) * bar_width / 2 for index in indices], subfolder_names, rotation=45, ha=\"right\")\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Image Size Distribution by Subfolder')\n",
    "    plt.legend(title=\"Image Size\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Set the path to the dataset directory\n",
    "dataset_size_analysis(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "executionInfo": {
     "elapsed": 1901,
     "status": "ok",
     "timestamp": 1752205985594,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "vxwlQ5pNI7KU",
    "outputId": "674a3aef-cc6e-496d-d197-bd514ded9b18"
   },
   "outputs": [],
   "source": [
    "# Preview photos\n",
    "\n",
    "def random_photos_from_folders(base_folder):\n",
    "    # Walk through all directories and files in the base_folder\n",
    "    for root, dirs, files in os.walk(base_folder):\n",
    "        # Filter to get only files that are images\n",
    "        images = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        if len(images) >= 4:  # Ensure there are at least 4 images\n",
    "            selected_images = random.sample(images, 4)  # Randomly select 4 images\n",
    "\n",
    "            # Display selected images\n",
    "            fig, axs = plt.subplots(1, 4, figsize=(12, 2))  # Create a 1x4 grid of plots\n",
    "            for idx, img_name in enumerate(selected_images):\n",
    "                img_path = os.path.join(root, img_name)\n",
    "                img = Image.open(img_path)\n",
    "                axs[idx].imshow(img)\n",
    "                axs[idx].axis('off')  # Hide axes\n",
    "\n",
    "                # Extract sub-folder name from the root path\n",
    "                subfolder_name = os.path.basename(root)\n",
    "                # Set the title to include image name and sub-folder name\n",
    "                axs[idx].set_title(f\"{img_name}\\n({subfolder_name})\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "# Path to the folder containing sub-folders with images\n",
    "\n",
    "random_photos_from_folders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1752205985834,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "9g54cEy8I8Bg",
    "outputId": "383a1f9b-3c8b-446f-935f-b0b265f858ce"
   },
   "outputs": [],
   "source": [
    "# Getting the names of classes\n",
    "class_dirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "\n",
    "# create data path and their labeles\n",
    "data = []\n",
    "labels = []\n",
    "extensions = [\"jpg\", \"JPG\", \"jpeg\", \"JPEG\", \"png\", \"PNG\", \"bmp\", \"BMP\", \"gif\", \"GIF\"]\n",
    "\n",
    "for i in class_dirs:\n",
    "    class_label = i\n",
    "    image_files = []\n",
    "    for ext in extensions:\n",
    "        # Search for files with each extension and extend the image_files list\n",
    "        image_files.extend(glob.glob(os.path.join(path, i, f\"*.{ext}\")))\n",
    "    data.extend(image_files)\n",
    "    labels.extend([class_label] * len(image_files))\n",
    "\n",
    "# Check if lists are still empty\n",
    "if not data:\n",
    "    print(\"No files were found. Check your directory paths and file formats.\")\n",
    "else:\n",
    "    print(\"Files found and listed.\")\n",
    "\n",
    "\n",
    "# Create a DataFrame with the image paths and labels\n",
    "df = pd.DataFrame({\n",
    "'filename': data,\n",
    "'class': labels\n",
    "})\n",
    "\n",
    "\n",
    "# Shuffle the dataset by rows\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1752205985836,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "nNuXEvJQJBo5",
    "outputId": "7b4e0d2e-e91e-4fe1-a92d-f30ef0db98f0"
   },
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encodings\n",
    "label_encoder = LabelEncoder()\n",
    "label = label_encoder.fit_transform(df['class'])\n",
    "df['class'] = label\n",
    "\n",
    "# check number assigned to each class\n",
    "# Get the class names and corresponding integer encodings\n",
    "class_names = label_encoder.classes_\n",
    "class_numbers = label_encoder.transform(label_encoder.classes_)\n",
    "\n",
    "# Print class names with the assigned numbers\n",
    "class_dict = dict(zip(class_names, class_numbers))\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1752205985841,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "5W4yDaIsJE5d",
    "outputId": "26b724c7-2de9-4acd-e004-fd216698049b"
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1752205985859,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "skaNzFTgJHB6",
    "outputId": "bfd8d1dc-30c5-4357-c6b0-b3977076a3f3"
   },
   "outputs": [],
   "source": [
    "# Check the balance of the classes\n",
    "print(df['class'].value_counts(normalize=True))\n",
    "print('------'*10)\n",
    "\n",
    "# Split the data into train+validation and test sets\n",
    "train_plus_val, test = train_test_split(df, test_size=0.2, stratify=df['class'], random_state=42)\n",
    "\n",
    "# Split the train+validation set into train and validation sets\n",
    "train, val = train_test_split(train_plus_val, test_size=0.25, stratify=train_plus_val['class'], random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Now you have:\n",
    "# train: 60% of the data\n",
    "# val: 20% of the data\n",
    "# test: 20% of the data\n",
    "\n",
    "# Confirm the distribution across splits\n",
    "print(\"Training set:\")\n",
    "print(train['class'].value_counts(normalize=True))\n",
    "print('------'*10)\n",
    "\n",
    "\n",
    "print(\"Validation set:\")\n",
    "print(val['class'].value_counts(normalize=True))\n",
    "print('------'*10)\n",
    "\n",
    "\n",
    "print(\"Test set:\")\n",
    "print(test['class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuY99IVlJR9g"
   },
   "outputs": [],
   "source": [
    "train_links, train_labels = train['filename'].values , train['class'].values\n",
    "val_links , val_labels = val['filename'].values , val['class'].values\n",
    "test_links, test_labels = test['filename'].values , test['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IMuMp-pJXxv"
   },
   "outputs": [],
   "source": [
    "# Create a Function to Load and Preprocess Images\n",
    "# tf.cond is a TensorFlow operation that allows for conditional execution based on the value of a tensor.\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(path, label, data_augmentation=True):\n",
    "    # Read the image file\n",
    "    image = tf.io.read_file(path)\n",
    "\n",
    "    # Extract file extension\n",
    "    file_extension = tf.strings.split(path, '.')[-1]\n",
    "\n",
    "    # Decode based on file extension using tf.cond\n",
    "    def decode_jpeg():\n",
    "        return tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    def decode_png():\n",
    "        return tf.image.decode_png(image, channels=3)\n",
    "\n",
    "    def decode_bmp():\n",
    "        return tf.image.decode_bmp(image, channels=3)\n",
    "\n",
    "    def decode_gif():\n",
    "        # Decode GIF and take the first frame\n",
    "        return tf.squeeze(tf.image.decode_gif(image), axis=0)\n",
    "\n",
    "    # Handle each format\n",
    "    image = tf.cond(tf.math.equal(file_extension, 'jpg'), decode_jpeg,\n",
    "            lambda: tf.cond(tf.math.equal(file_extension, 'jpeg'), decode_jpeg,\n",
    "            lambda: tf.cond(tf.math.equal(file_extension, 'png'), decode_png,\n",
    "            lambda: tf.cond(tf.math.equal(file_extension, 'bmp'), decode_bmp,\n",
    "            lambda: tf.cond(tf.math.equal(file_extension, 'gif'), decode_gif,\n",
    "            decode_jpeg)))))\n",
    "\n",
    "    # Resize and normalize\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = image / 255.0  # Normalize to [0, 1] range\n",
    "\n",
    "    # Apply data augmentation if in training mode\n",
    "    if data_augmentation == True:\n",
    "        # Randomly flip the image horizontally\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "        # Randomly flip the image vertically\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "        # Randomly rotate the image\n",
    "        image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "        # Randomly adjust brightness\n",
    "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "\n",
    "        # Randomly zoom in\n",
    "        image = tf.image.resize_with_crop_or_pad(image, 266, 266)  # Zoom in slightly\n",
    "        image = tf.image.random_crop(image, size=[256, 256, 3])\n",
    "\n",
    "        # Randomly adjust contrast\n",
    "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXn7DaZFJbq9"
   },
   "outputs": [],
   "source": [
    "# create TensorFlow datasets for each split\n",
    "# When loading datasets, pass the data_augmentation flag True or False to apply or skip augmentations:\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices( (train_links , train_labels) )\n",
    "train_dataset = train_dataset.map(lambda x, y: load_and_preprocess_image(x, y, data_augmentation=True), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices( (val_links , val_labels) )\n",
    "val_dataset = val_dataset.map(lambda x, y: load_and_preprocess_image(x, y, data_augmentation=False), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices( (test_links , test_labels) )\n",
    "test_dataset = test_dataset.map(lambda x, y: load_and_preprocess_image(x, y, data_augmentation=False), num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1752205987908,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "Qpuq8ECMJe4q",
    "outputId": "52c6c70e-5a58-4baa-fb06-4d02f93a781e"
   },
   "outputs": [],
   "source": [
    "# Iterate over the dataset and print the first few elements\n",
    "for data_element, label_element in train_dataset.take(1):  # Adjust the number to print more/less\n",
    "    print(f\"Data: {data_element.numpy()}, Label: {label_element.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1752205988046,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "VhID7ifnJiBI",
    "outputId": "7318da7d-44e6-4e25-cf3c-0dbe6699c6f9"
   },
   "outputs": [],
   "source": [
    "# Iterate over the dataset and print the first few elements\n",
    "for data_element, label_element in train_dataset.take(1):  # Adjust the number to print more/less\n",
    "    print(f\"Data: {data_element.numpy().shape}, Label: {label_element.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onk17YqaJmWs"
   },
   "outputs": [],
   "source": [
    "#prepare your datasets for model training and evaluation\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(buffer_size= tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "executionInfo": {
     "elapsed": 1560,
     "status": "ok",
     "timestamp": 1752205989649,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "2z1zQMF6JrI-",
    "outputId": "ec3b4456-f69f-4f4c-b955-968e3bf68ed2"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    # First Block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', input_shape=(256, 256, 3), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "\n",
    "    # Second Block\n",
    "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # Second Block\n",
    "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # Second Block\n",
    "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "\n",
    "\n",
    "    # Global Average Pooling instead of Flatten\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    layers.Dense(512,activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_names), activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5254455,
     "status": "ok",
     "timestamp": 1752211244101,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "6yddWIskJwnw",
    "outputId": "5b91a4c6-16a5-4dc2-8f3c-167c712d2cc2"
   },
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback to monitor the validation accuracy\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitoring validation accuracy\n",
    "    patience=12,  # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,\n",
    "    mode='max',  # Stops training when the quantity monitored has stopped increasing\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=r'/home/mojtaba/eye_diseases_classification project/saved model/best_model_custom.keras',  # Path to save the model file\n",
    "    monitor='val_loss',  # Change to val_loss to monitor the validation loss\n",
    "    verbose=1,\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    mode='min'  # Save the model when the monitored metric has minimized\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# # Fit the model\n",
    "history = model.fit(\n",
    "    x = train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    epochs = 200,\n",
    "    callbacks=[early_stopping , model_checkpoint]  # Add the EarlyStopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1752211244387,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "22cd60bf",
    "outputId": "e05e50a8-ab33-416c-ea7a-2428fd3d9145"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the path where you want to save the history\n",
    "history_save_path = '/content/drive/MyDrive/model_history.json' # You can change this path\n",
    "\n",
    "# Convert the history dictionary to a JSON string and save it\n",
    "with open(history_save_path, 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "print(f\"Training history saved to {history_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1752211244405,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "51ed2760",
    "outputId": "059911e9-a943-4db6-ef2f-b72dfb01e87d"
   },
   "outputs": [],
   "source": [
    "# Create a dummy history object with placeholder data\n",
    "# Replace the dictionary with actual data if you have it from a previous training run\n",
    "history = type('History', (object,), {\n",
    "    'history': {\n",
    "        'accuracy': [0.5, 0.6],\n",
    "        'val_accuracy': [0.4, 0.5],\n",
    "        'loss': [0.8, 0.7],\n",
    "        'val_loss': [0.9, 0.8]\n",
    "    }\n",
    "})()\n",
    "\n",
    "print(\"Dummy history object created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 957
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1752211244641,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "UH-y6lElJ0Hw",
    "outputId": "739c693a-15c9-4790-e504-1aa45714a014"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(13,5))\n",
    "#plt.plot(history.history['accuracy'],color=\"#E74C3C\", marker='o')\n",
    "#plt.plot(history.history['val_accuracy'], color='#641E16', marker='h')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.plot(history.history['loss'],color=\"#E74C3C\", marker='o')\n",
    "plt.plot(history.history['val_loss'], color='#641E16', marker='h')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend( ['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59210,
     "status": "ok",
     "timestamp": 1752211303844,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "3bJqWwPPKFt7",
    "outputId": "50ef662d-23ba-4d45-f76c-4d85abfba70a"
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "# If the best model is captured by the early stopping mechanism then best_model = model\n",
    "# best_model = model\n",
    "\n",
    "best_model = load_model(r'/home/mojtaba/eye_diseases_classification project/saved model/best_model_custom.keras')\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_accuracy = best_model.evaluate(train_dataset)\n",
    "val_loss, val_accuracy = best_model.evaluate(val_dataset)\n",
    "test_loss, test_accuracy = best_model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"train loss: {train_loss}\")\n",
    "print(f\"train accuracy: {train_accuracy}\")\n",
    "print('----'*6)\n",
    "print(f\"val loss: {val_loss}\")\n",
    "print(f\"val accuracy: {val_accuracy}\")\n",
    "print('----'*6)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10273,
     "status": "ok",
     "timestamp": 1752211314120,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "NCWAFoFOKGeY",
    "outputId": "94a8dbf2-bb63-4b91-cdff-b0d8a9cd3167"
   },
   "outputs": [],
   "source": [
    "# Assuming best_model is your trained Keras model\n",
    "\n",
    "# Get the predicted labels from the model\n",
    "y_pred = np.argmax( best_model.predict(test_dataset) , axis=1 ) # Convert probabilities to class indices\n",
    "y_true = test_labels\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Get the class labels from the LabelEncoder\n",
    "class_labels = label_encoder.classes_\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(y_true, y_pred, target_names=class_labels)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1752211314445,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "Ol1o03Q3KJM2",
    "outputId": "0fd2db4e-90eb-4c43-e4b0-de7bae22833a"
   },
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "print('Total Number Of Test data: ', len(test_labels))\n",
    "\n",
    "sn.set_style(\"white\")\n",
    "def plot_confusion_matrix(conf_mat, classes):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7,7)) # change the plot size\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=classes)\n",
    "    disp = disp.plot(include_values=True,cmap='viridis', ax=ax, xticks_rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Get your confusion matrix\n",
    "conf_mat = conf_mat\n",
    "\n",
    "# Using label_encoder.classes_ guarantees that class_names matches\n",
    "# the order that was used during the one-hot encoding process\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Now plot using the function\n",
    "plot_confusion_matrix(conf_mat, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1l5rRaUpS-xVXT8LpQKj8NQ9ryIR3ydcD"
    },
    "executionInfo": {
     "elapsed": 4603,
     "status": "ok",
     "timestamp": 1752211319039,
     "user": {
      "displayName": "JORGE LUIS YOVERA CHAVEZ",
      "userId": "14550606723561152617"
     },
     "user_tz": 300
    },
    "id": "XC6fUp7vKMHS",
    "outputId": "6f72044a-fc73-479a-de7b-734e6db7c683"
   },
   "outputs": [],
   "source": [
    "# probability explanation in below function:\n",
    "# For example, if the model predicts an image as class B with a probability of 0.7 (or 70%),\n",
    "# the plot will show \"Probability: 70%\".\n",
    "# This means the model is 70% confident that the image belongs to class B.\n",
    "\n",
    "\n",
    "def plot_test_predictions(model, test_dataset, class_labels, num_images=20):\n",
    "    \"\"\"\n",
    "    Plots the predictions of a model on the test dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained Keras model to be used for prediction.\n",
    "    - test_dataset: TensorFlow dataset containing the test images and labels.\n",
    "    - class_labels: List of class labels.\n",
    "    - num_images: Number of test images to plot (default is 20).\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize lists to accumulate images and labels\n",
    "    images = []\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    pred_probs = []\n",
    "\n",
    "    for batch_images, batch_labels in test_dataset:\n",
    "        # Predict on the batch\n",
    "        batch_pred_probs = model.predict(batch_images)\n",
    "        batch_pred_labels = np.argmax(batch_pred_probs, axis=1)\n",
    "\n",
    "        # Accumulate images and labels\n",
    "        images.extend(batch_images)\n",
    "        true_labels.extend(batch_labels)\n",
    "        pred_labels.extend(batch_pred_labels)\n",
    "        pred_probs.extend(np.max(batch_pred_probs, axis=1) * 100)\n",
    "\n",
    "        if len(images) >= num_images:\n",
    "            break\n",
    "\n",
    "    # Plot the images with predictions\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        actual_label = class_labels[true_labels[i]]\n",
    "        predicted_label = class_labels[pred_labels[i]]\n",
    "        probability = pred_probs[i]  # Probability of the predicted class\n",
    "\n",
    "        color = 'green' if actual_label == predicted_label else 'red'\n",
    "        plt.title(f\"Actual Label: {actual_label}\\nPrediction: {predicted_label}\\nProbability: {probability:.2f}%\",\n",
    "                  color=color, fontsize=12)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use the function\n",
    "plot_test_predictions(best_model, test_dataset, class_labels=class_names, num_images=20)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO8rqqTXm+CpBND0PESHmEO",
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1Hzi4W6ao0k0OLzryWQNlsVQJXYXAjrMo",
     "timestamp": 1752199427945
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
